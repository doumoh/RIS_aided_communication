{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/doumoh/RIS_aided_communication/blob/main/Neural_Receiver_for_OFDM_SIMO___.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y sionna tensorflow tensorflow-probability numpy\n",
        "!pip install sionna==0.19 tensorflow tensorflow-probability numpy --upgrade\n",
        "!pip uninstall -y mitsuba\n",
        "!pip install mitsuba==3.5.0"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b9fjsygPvxcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.getenv(\"CUDA_VISIBLE_DEVICES\") is None:\n",
        "    gpu_num = 0 # Use \"\" to use the CPU\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "# Import Sionna\n",
        "try:\n",
        "    import sionna\n",
        "except ImportError as e:\n",
        "    # Install Sionna if package is not already installed\n",
        "    import os\n",
        "    os.system(\"pip install sionna==0.19\")\n",
        "    import sionna\n",
        "\n",
        "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
        "# For more details, see https://www.tensorflow.org/guide/gpu\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
        "    except RuntimeError as e:\n",
        "        print(e)\n",
        "# Avoid warnings from TensorFlow\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "sionna.config.seed = 42 # Set seed for reproducible random number generation\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\n",
        "from tensorflow.nn import relu\n",
        "\n",
        "from sionna.channel.tr38901 import Antenna, AntennaArray\n",
        "from sionna.channel import OFDMChannel\n",
        "from sionna.mimo import StreamManagement\n",
        "from sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer, RemoveNulledSubcarriers, ResourceGridDemapper\n",
        "from sionna.utils import BinarySource, ebnodb2no, insert_dims, flatten_last_dims, log10, expand_to_rank\n",
        "from sionna.fec.ldpc.encoding import LDPC5GEncoder\n",
        "from sionna.fec.ldpc.decoding import LDPC5GDecoder\n",
        "from sionna.mapping import Mapper, Demapper\n",
        "from sionna.utils.metrics import compute_ber\n",
        "from sionna.utils import sim_ber\n",
        "from sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera\n",
        "from sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset\n",
        "from sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\n",
        "from sionna.utils import compute_ber, ebnodb2no, PlotBER\n",
        "from sionna.mimo import StreamManagement\n",
        "from sionna.rt import load_scene, Transmitter, Receiver, RIS, PlanarArray, normalize, Camera\n",
        "from sionna import PI\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/My Drive/Blender Scene/rxx.xml'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcP--qxFv1gk",
        "outputId": "c824034b-b32f-4f78-e21b-ee1c965ef665"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load scene\n",
        "scene = load_scene(file_path)\n",
        "# Configure antenna array for all transmitters\n",
        "scene.tx_array = PlanarArray(num_rows=1,\n",
        "                             num_cols=1,\n",
        "                             vertical_spacing=0.5,\n",
        "                             horizontal_spacing=0.5,\n",
        "                             pattern=\"dipole\",\n",
        "                             polarization=\"H\")\n",
        "\n",
        "# Configure antenna array for all receivers\n",
        "scene.rx_array = PlanarArray(num_rows=1,\n",
        "                             num_cols=1,\n",
        "                             vertical_spacing=0.5,\n",
        "                             horizontal_spacing=0.5,\n",
        "                             pattern=\"dipole\",\n",
        "                             polarization=\"cross\")\n",
        "\n",
        "# Create transmitter\n",
        "tx = Transmitter(name=\"tx\",\n",
        "                 position=[-4,3,3])\n",
        "\n",
        "# Add transmitter\n",
        "scene.add(tx)\n",
        "\n",
        "width = 8 * scene.wavelength # Width [m] for 16*16 RIS elements\n",
        "num_rows = num_cols = int(width/(0.5*scene.wavelength))\n",
        "ris = RIS(name=\"ris\",\n",
        "          position=[7.5,-3,2],\n",
        "          orientation=[PI/2,0,0],\n",
        "          num_rows=num_rows,\n",
        "          num_cols=num_cols)\n",
        "\n",
        "scene.add(ris)\n",
        "\n",
        "# Create a receiver\n",
        "rx = Receiver(name=\"rx\",\n",
        "              position=[3,4.5,3.5],\n",
        "              orientation=[0,0,0])\n",
        "\n",
        "# Add receiver\n",
        "scene.add(rx)\n"
      ],
      "metadata": {
        "id": "GzjvzP6WwAQH"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sionna.rt.solver_paths import SolverPaths # Import SolverPaths to modify the _ris_transition_matrices function\n",
        "class CustomSolverPaths(SolverPaths):\n",
        "    def _ris_transition_matrices(self, ris_paths, ris_paths_tmp):\n",
        "        # Compute scattering coefficients\n",
        "        sc = [tf.reduce_sum(r(), axis=0) for r in self._scene.ris.values()]\n",
        "        sc = tf.concat(sc, axis=0)\n",
        "        sc = sc[tf.newaxis, tf.newaxis, ...]\n",
        "\n",
        "\n",
        "        # Coefficient calculation\n",
        "        coef = tf.cast(4 * PI, self._rdtype)\n",
        "        coef /= tf.reduce_prod(ris_paths_tmp.distances, axis=0)\n",
        "        coef *= tf.cast(tf.sqrt(tx.power_dbm * 0.001 * 120 * PI * 2 * 66), self._rdtype)\n",
        "        coef = tf.complex(coef, tf.cast(0, self._rdtype))\n",
        "\n",
        "        # Differentiable phase decision: use magnitude of imag part\n",
        "        imag_part = tf.math.imag(sc)\n",
        "\n",
        "        # Sharpen sigmoid to approximate a step function: large scaling factor\n",
        "        sharpness = 100000000.0  # Higher value = closer to hard decision\n",
        "        phase_weight = tf.sigmoid(sharpness * imag_part)  # Step at imag_part = 0\n",
        "\n",
        "        # Now interpolate between 0° for real (imag == 0) and 165° for complex (non-zero imag)\n",
        "        phase_deg = phase_weight * 2 * 165.0\n",
        "\n",
        "\n",
        "        # Convert to radians and cast\n",
        "        phase_rad = phase_deg * (np.pi / 180.0)\n",
        "        phase_rad = tf.cast(phase_rad, self._rdtype)\n",
        "\n",
        "\n",
        "        # Compute complex phase rotation\n",
        "        sigma_eff_value = 0.001  # Scalar value\n",
        "        sqrt_sigma = tf.sqrt(tf.cast(sigma_eff_value, self._rdtype))\n",
        "        sqrt_sigma = tf.complex(sqrt_sigma, tf.cast(0, self._rdtype))  # Ensure sqrt_sigma is complex\n",
        "        sigma_phi_matrix = sqrt_sigma * tf.exp(\n",
        "            tf.complex(0.0, phase_rad)  # Ensure exp result is complex\n",
        "        )\n",
        "\n",
        "        # Apply coefficient modification with masking\n",
        "        coef *= sigma_phi_matrix\n",
        "        coef = tf.where(ris_paths.mask, coef, tf.cast(0, coef.dtype))\n",
        "\n",
        "        # Create polarization-preserving transition matrices\n",
        "        coef = coef[..., tf.newaxis, tf.newaxis]\n",
        "        ris_mat_t = coef * tf.eye(2, batch_shape=[1, 1, 1], dtype=self._dtype)\n",
        "\n",
        "        return ris_mat_t\n",
        "scene._solver_paths = CustomSolverPaths(scene) # Replace to custom SolverPaths\n"
      ],
      "metadata": {
        "id": "QuWpg2QcwFPx"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SNR range for evaluation and training\n",
        "ebno_db_min = -5.0\n",
        "ebno_db_max = 10.0\n",
        "\n",
        "## OFDM configuration\n",
        "subcarrier_spacing = 30e3 # Hz\n",
        "fft_size = 128 # Number of subcarriers\n",
        "num_ofdm_symbols = 14 # Number of OFDM symbols\n",
        "dc_null = True # Null the DC subcarrier\n",
        "num_guard_carriers = [5, 6] # Number of guard carriers on each side\n",
        "pilot_pattern = \"kronecker\" # Pilot pattern\n",
        "pilot_ofdm_symbol_indices = [2, 11] # Index of OFDM symbols carrying pilots\n",
        "#pilot_ofdm_symbol_indices = [2] # Index of OFDM symbols carrying pilots\n",
        "cyclic_prefix_length = 0 # Simulation in frequency domain.\n",
        "\n",
        "## Modulation and coding configuration\n",
        "num_bits_per_symbol = 2 # QPSK\n",
        "coderate = 0.5 # Coderate for LDPC code\n",
        "\n",
        "## Neural receiver configuration\n",
        "num_conv_channels = 12 # Number of convolutional channels for the convolutional layers forming the neural receiver\n",
        "\n",
        "## Training configuration\n",
        "training_batch_size = 64 # Training batch size\n",
        "model_weights_path = \"neural_receiver_weights\" # Location to save the neural receiver weights once training is done\n",
        "stream_manager = StreamManagement(np.array([[1]]), # Receiver-transmitter association matrix\n",
        "                                  1)               # One stream per transmitter\n",
        "resource_grid = ResourceGrid(num_ofdm_symbols = num_ofdm_symbols,\n",
        "                             fft_size = fft_size,\n",
        "                             subcarrier_spacing = subcarrier_spacing,\n",
        "                             num_tx = 1,\n",
        "                             num_streams_per_tx = 1,\n",
        "                             cyclic_prefix_length = cyclic_prefix_length,\n",
        "                             dc_null = dc_null,\n",
        "                             pilot_pattern = pilot_pattern,\n",
        "                             pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices,\n",
        "                             num_guard_carriers = num_guard_carriers)\n",
        "# Codeword length. It is calculated from the total number of databits carried by the resource grid, and the number of bits transmitted per resource element\n",
        "n = int(resource_grid.num_data_symbols*num_bits_per_symbol)\n",
        "# Number of information bits per codeword\n",
        "k = int(n*coderate)"
      ],
      "metadata": {
        "id": "nUaStXEMwbjq"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = scene.compute_paths(max_depth=5,\n",
        "                            num_samples=1e6)\n",
        "\n",
        "a, tau = paths.cir()\n",
        "# Compute frequencies of subcarriers and center around carrier frequency\n",
        "frequencies = subcarrier_frequencies(fft_size, subcarrier_spacing)\n",
        "\n",
        "# Compute the frequency response of the channel at frequencies.\n",
        "h_freq = cir_to_ofdm_channel(frequencies,\n",
        "                             a,\n",
        "                             tau,\n",
        "                             normalize=True)"
      ],
      "metadata": {
        "id": "IWO8Uyjcwp_l"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_source = BinarySource()\n",
        "mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
        "rg_mapper = ResourceGridMapper(resource_grid)\n",
        "batch_size = 64\n",
        "ebno_db = tf.fill([batch_size], 25.0)\n",
        "no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
        "c = binary_source([batch_size, 1, 1, n])\n",
        "x = mapper(c)\n",
        "x_rg = rg_mapper(x)\n",
        "channel = ApplyOFDMChannel(add_awgn=True)"
      ],
      "metadata": {
        "id": "XeIzaa7yy7Ay"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_subcarriers(ofdm_symbol, dc_null=True, guard_left=5, guard_right=6):\n",
        "    # Remove guards\n",
        "    active = ofdm_symbol[guard_left:-guard_right]\n",
        "    if dc_null:\n",
        "        # Remove DC (middle subcarrier)\n",
        "        dc_idx = (len(active)) // 2\n",
        "        active = tf.concat([active[:dc_idx], active[dc_idx+1:]], axis=0)\n",
        "    return active\n",
        "# Keep track of best loss and corresponding phase configuration\n",
        "best_loss = np.inf\n",
        "# Create trainable variables for phase (continuous)\n",
        "phase_var = tf.Variable(tf.zeros_like(ris.phase_profile.values), trainable=True)\n",
        "best_phase_config = tf.Variable(tf.zeros_like(ris.phase_profile.values), trainable=False)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "@tf.custom_gradient\n",
        "def binarize_phase(x):\n",
        "    pi = tf.constant(np.pi, dtype=tf.float32)\n",
        "    binary = tf.where(x > 0, pi, 0.0)         # Anything > 0 --> pi else 0\n",
        "    def grad(dy):\n",
        "        return dy * tf.cast(tf.logical_and(x > -1.0, x < 1.0), tf.float32) # Accept gradient between -1.5 and 1.5 ,other set to zero (no update)\n",
        "    return binary, grad\n",
        "\n",
        "def to_db(x):\n",
        "    return 10*tf.math.log(x)/tf.math.log(10.)\n",
        "# Training step\n",
        "def train_step():\n",
        "    global best_loss, best_phase_config\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Apply binarized and differentiable phase\n",
        "        bin_phase = binarize_phase(phase_var)\n",
        "\n",
        "        # Apply binarized phase to RIS\n",
        "        ris.phase_profile.values = bin_phase\n",
        "\n",
        "        # Compute channel response and output\n",
        "        paths = scene.compute_paths(max_depth=5, num_samples=1e6)\n",
        "        a, tau = paths.cir()\n",
        "        frequencies = subcarrier_frequencies(fft_size, subcarrier_spacing)\n",
        "        h_freq = cir_to_ofdm_channel(frequencies, a, tau, normalize=True)\n",
        "        y = channel([x_rg, h_freq, no])\n",
        "\n",
        "        # Extract pilots and compute loss\n",
        "        y_pilots_sym2 = y[0, 0, 0, 2]  # shape: (128,)\n",
        "        active_sym2 = clean_subcarriers(y_pilots_sym2)\n",
        "        energy_per_symbol2 = tf.abs(active_sym2) ** 2\n",
        "        loss1 = tf.reduce_sum(energy_per_symbol2)\n",
        "        print(loss1)\n",
        "        # Compute loss on pilot energy\n",
        "        y_pilots_sym11 = y[0, 0, 0, 11]\n",
        "        active_sym11 = clean_subcarriers(y_pilots_sym11)\n",
        "        energy_per_symbol11 = tf.abs(active_sym11) ** 2\n",
        "        loss2 = tf.reduce_sum(energy_per_symbol11)\n",
        "        print(loss2)\n",
        "        loss = (loss1 + loss2)\n",
        "\n",
        "    # Check if this is a better phase config (i.e., lower loss)\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "        best_phase_config.assign(phase_var)  # Save current phase_var\n",
        "       # ris.phase_profile.values = phase_var\n",
        "        grads = tape.gradient(loss, [phase_var])\n",
        "        optimizer.apply_gradients(zip(grads, [phase_var]))\n",
        "        print(f\" Accepted update: Loss = {loss.numpy():.2f}\")\n",
        "    else:\n",
        "        phase_var.assign(best_phase_config)  # Revert to best\n",
        "        print(f\" Rejected update: Loss = {loss.numpy():.2f} (Best = {best_loss.numpy():.2f})\")\n",
        "\n",
        "    return loss\n",
        "num_iterations = 15\n",
        "for i in range(num_iterations):\n",
        "    loss = train_step()\n",
        "    print(f\"Iteration {i}: Loss = {loss.numpy():.2f} \")\n"
      ],
      "metadata": {
        "id": "VJ44rLJjwMmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(Layer):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n",
        "        self._layer_norm_1 = LayerNormalization(axis=(-1, -2, -3))\n",
        "        self._conv_1 = Conv2D(filters=num_conv_channels,\n",
        "                              kernel_size=[2,2],\n",
        "                              padding='same',\n",
        "                              activation=None)\n",
        "        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n",
        "        self._layer_norm_2 = LayerNormalization(axis=(-1, -2, -3))\n",
        "        self._conv_2 = Conv2D(filters=num_conv_channels,\n",
        "                              kernel_size=[2,2],\n",
        "                              padding='same',\n",
        "                              activation=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z = self._layer_norm_1(inputs)\n",
        "        z = relu(z)\n",
        "        z = self._conv_1(z)\n",
        "        z = self._layer_norm_2(z)\n",
        "        z = relu(z)\n",
        "        z = self._conv_2(z)\n",
        "        z = z + inputs\n",
        "\n",
        "        return z\n",
        "\n",
        "class NeuralReceiver(Layer):\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        # Input convolution\n",
        "        self._input_conv = Conv2D(filters=num_conv_channels,\n",
        "                                  kernel_size=[2,2],\n",
        "                                  padding='same',\n",
        "                                  activation=None)\n",
        "        # Residual blocks\n",
        "        self._res_block_1 = ResidualBlock()\n",
        "        self._res_block_2 = ResidualBlock()\n",
        "        self._res_block_3 = ResidualBlock()\n",
        "        self._res_block_4 = ResidualBlock()\n",
        "        # Output conv\n",
        "        self._output_conv = Conv2D(filters=num_bits_per_symbol,\n",
        "                                   kernel_size=[2,2],\n",
        "                                   padding='same',\n",
        "                                   activation=None)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y, no = inputs\n",
        "\n",
        "        # Feeding the noise power in log10 scale\n",
        "        no = log10(no)\n",
        "        # Stacking the real and imaginary components of the different antennas along the 'channel' dimension\n",
        "        y = tf.transpose(y, [0, 2, 3, 1]) # Putting antenna dimension last\n",
        "        no = insert_dims(no, 3, 1)\n",
        "        no = tf.tile(no, [1, y.shape[1], y.shape[2], 1])\n",
        "        z = tf.concat([tf.math.real(y),\n",
        "                       tf.math.imag(y),\n",
        "                       no], axis=-1)\n",
        "        # Input conv\n",
        "        z = self._input_conv(z)\n",
        "        # Residual blocks\n",
        "        z = self._res_block_1(z)\n",
        "        z = self._res_block_2(z)\n",
        "        z = self._res_block_3(z)\n",
        "        z = self._res_block_4(z)\n",
        "        # Output conv\n",
        "        z = self._output_conv(z)\n",
        "\n",
        "        return z"
      ],
      "metadata": {
        "id": "P9I_ZXY3wmng"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class E2ESystem(Model):\n",
        "\n",
        "\n",
        "    def __init__(self, system, training=False):\n",
        "        super().__init__()\n",
        "        self._system = system\n",
        "        self._training = training\n",
        "\n",
        "        ######################################\n",
        "        ## Transmitter\n",
        "        self._binary_source = BinarySource()\n",
        "        if not training:\n",
        "            self._encoder = LDPC5GEncoder(k, n)\n",
        "        self._mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
        "        self._rg_mapper = ResourceGridMapper(resource_grid)\n",
        "        ######################################\n",
        "        ## Channel\n",
        "        self._channel = ApplyOFDMChannel(add_awgn=True)\n",
        "        ######################################\n",
        "        ## Receiver\n",
        "        if \"baseline\" in system:\n",
        "            if system == 'baseline-perfect-csi':  # Perfect CSI\n",
        "                self._removed_null_subc = RemoveNulledSubcarriers(resource_grid)\n",
        "            elif system == 'baseline-ls-estimation':  # LS estimation\n",
        "                self._ls_est = LSChannelEstimator(resource_grid, interpolation_type=\"nn\")\n",
        "            # Components required by both baselines\n",
        "            self._lmmse_equ = LMMSEEqualizer(resource_grid, stream_manager)\n",
        "            self._demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n",
        "\n",
        "        elif system == \"neural-receiver\":  # Neural receiver\n",
        "            self._neural_receiver = NeuralReceiver()\n",
        "            self._rg_demapper = ResourceGridDemapper(resource_grid, stream_manager)  # Used to extract data-carrying resource elements\n",
        "        if not training:\n",
        "            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n",
        "    @tf.function\n",
        "    def call(self, batch_size, ebno_db):\n",
        "\n",
        "        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n",
        "        if len(ebno_db.shape) == 0:\n",
        "            ebno_db = tf.fill([batch_size], ebno_db)\n",
        "        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
        "        if self._training:\n",
        "            c = self._binary_source([batch_size, 1, 1, n])\n",
        "        else:\n",
        "            b = self._binary_source([batch_size, 1, 1, k])\n",
        "            c = self._encoder(b)\n",
        "        # Modulation\n",
        "        x = self._mapper(c)\n",
        "        x_rg = self._rg_mapper(x)\n",
        "        no_ = expand_to_rank(no, tf.rank(x_rg))\n",
        "        # channel\n",
        "        y   = self._channel([x_rg,h_freq, no_])\n",
        "        if \"baseline\" in self._system:\n",
        "            if self._system == 'baseline-perfect-csi':\n",
        "                h_hat = self._removed_null_subc(h_freq) # Extract non-null subcarriers\n",
        "                batch_size = tf.shape(y)[0]  # Or pass batch_size explicitly if available\n",
        "                # Tile h_hat across the batch dimension\n",
        "                h_hat = tf.tile(h_hat, [batch_size, 1, 1, 1, 1, 14, 1])\n",
        "                err_var = 0.0 # No channel estimation error when perfect CSI knowledge is assumed\n",
        "            elif self._system == 'baseline-ls-estimation':\n",
        "                h_hat, err_var = self._ls_est([y, no]) # LS channel estimation with nearest-neighbor\n",
        "\n",
        "\n",
        "            x_hat, no_eff = self._lmmse_equ([y, h_hat, err_var, no]) # LMMSE equalization\n",
        "            no_eff_= expand_to_rank(no_eff, tf.rank(x_hat))\n",
        "            llr = self._demapper([x_hat, no_eff_]) # Demapping\n",
        "        elif self._system == \"neural-receiver\":\n",
        "            # The neural receiver computes LLRs from the frequency domain received symbols and N0\n",
        "            y = tf.squeeze(y, axis=1)\n",
        "            llr = self._neural_receiver([y, no])\n",
        "            llr = insert_dims(llr, 2, 1) # Reshape the input to fit what the resource grid demapper is expected\n",
        "            llr = self._rg_demapper(llr) # Extract data-carrying resource elements. The other LLrs are discarded\n",
        "            llr = tf.reshape(llr, [batch_size, 1, 1, n]) # Reshape the LLRs to fit what the outer decoder is expected\n",
        "        if self._training:\n",
        "            # Compute and return BMD rate (in bit), which is known to be an achievable\n",
        "            # information rate for BICM systems.\n",
        "            # Training aims at maximizing the BMD rate\n",
        "            bce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr)\n",
        "            bce = tf.reduce_mean(bce)\n",
        "            rate = tf.constant(1.0, tf.float32) - bce/tf.math.log(2.)\n",
        "            return rate\n",
        "        else:\n",
        "            # Outer decoding\n",
        "            b_hat = self._decoder(llr)\n",
        "            return b,b_hat # for BER/BLER computation\n"
      ],
      "metadata": {
        "id": "3iS4lbolws4r"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_iterations = 300 # Number of training iterations\n",
        "training = True\n",
        "if training:\n",
        "    model = E2ESystem('neural-receiver', training=True)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    for i in range(num_training_iterations):\n",
        "        # Sampling a batch of SNRs\n",
        "        ebno_db = tf.random.uniform(shape=[], minval=ebno_db_min, maxval=ebno_db_max)\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            rate = model(training_batch_size, ebno_db)\n",
        "            loss = - rate\n",
        "            print(loss.numpy())\n",
        "\n",
        "        # Computing and applying gradients\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(loss, weights)\n",
        "        optimizer.apply_gradients(zip(grads, weights))\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}  Rate: {:.4f} bit'.format(i, num_training_iterations, rate.numpy()), end='\\r')\n",
        "\n"
      ],
      "metadata": {
        "id": "eHR8XBqAwvOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_weights(model, model_weights_path):\n",
        "    weights = model.get_weights()\n",
        "    with open(model_weights_path, 'wb') as f:\n",
        "        pickle.dump(weights, f)\n",
        "save_weights(model, model_weights_path)\n",
        "# Range of SNRs over which the systems are evaluated\n",
        "ebno_dbs = np.arange(ebno_db_min, # Min SNR for evaluation\n",
        "                     ebno_db_max, # Max SNR for evaluation\n",
        "                     1) # Step\n",
        "# function to load and set weights of a model\n",
        "def load_weights(model, model_weights_path):\n",
        "    model(1, tf.constant(10.0, tf.float32))\n",
        "    with open(model_weights_path, 'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "    model.set_weights(weights)\n",
        "# Dictionary storing the evaluation results\n",
        "BER = {}\n",
        "\n",
        "model = E2ESystem('baseline-perfect-csi')\n",
        "ber,_ = sim_ber(model, ebno_dbs, batch_size=64, num_target_block_errors=100, max_mc_iter=100)\n",
        "BER['baseline-perfect-csi-OpRIS'] = ber.numpy()\n",
        "\n",
        "model = E2ESystem('baseline-ls-estimation')\n",
        "ber,_ = sim_ber(model, ebno_dbs, batch_size=64, num_target_block_errors=100, max_mc_iter=100)\n",
        "BER['baseline-ls-estimation-OpRIS'] = ber.numpy()\n",
        "\n",
        "model = E2ESystem('neural-receiver')\n",
        "\n",
        "# Run one inference to build the layers and loading the weights\n",
        "model(1, tf.constant(10.0, tf.float32))\n",
        "with open(model_weights_path, 'rb') as f:\n",
        "    weights = pickle.load(f)\n",
        "model.set_weights(weights)\n",
        "\n",
        "# Evaluations\n",
        "ber,_ = sim_ber(model, ebno_dbs, batch_size=64, num_target_block_errors=100, max_mc_iter=100)\n",
        "BER['neural-receiver-OpRIS'] = ber.numpy()"
      ],
      "metadata": {
        "id": "fTfZ2dApw2CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_source = BinarySource()\n",
        "mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
        "rg_mapper = ResourceGridMapper(resource_grid)\n",
        "#neural_receiver = model_conventional._neural_receiver\n",
        "rg_demapper = ResourceGridDemapper(resource_grid, stream_manager)\n",
        "channel = ApplyOFDMChannel(add_awgn=True)\n",
        "batch_size = 64\n",
        "ebno_db = tf.fill([batch_size], 25.0)\n",
        "no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
        "## Transmitter\n",
        "# Generate codewords\n",
        "c = binary_source([batch_size, 1, 1, n])\n",
        "print(\"c shape: \", c.shape)\n",
        "# Map bits to QAM symbols\n",
        "x = mapper(c)\n",
        "print(\"x shape: \", x.shape)\n",
        "# Map the QAM symbols to a resource grid\n",
        "x_rg = rg_mapper(x)\n",
        "print(\"x_rg shape: \", x_rg.shape)\n",
        "print(\"h_freq shape: \", h_freq.shape)\n",
        "######################################\n",
        "## Channel\n",
        "no_ = expand_to_rank(no, tf.rank(x_rg))\n",
        "print(\"no shape: \", no.shape)\n",
        "print(\"no_ shape: \", no_.shape)\n",
        "# Apply channel\n",
        "channel = ApplyOFDMChannel(add_awgn=True)\n",
        "y = channel([x_rg, h_freq, no])\n",
        "print(\"y shape: \", y.shape)\n",
        "######################################\n",
        "#_lmmse_equ = LMMSEEqualizer(resource_grid, stream_manager, )\n",
        "##_removed_null_subc = RemoveNulledSubcarriers(resource_grid)\n",
        "######################################\n",
        "## Receiver\n",
        "_lmmse_equ = LMMSEEqualizer(resource_grid, stream_manager)\n",
        "_demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n",
        "_ls_est = LSChannelEstimator(resource_grid, interpolation_type=\"nn\")\n",
        "# The neural receiver computes LLRs from the frequency domain received symbols and N0\n",
        "#y = tf.squeeze(y, axis=1)\n",
        "#h_hat = _removed_null_subc(h_freq) # Extract non-null subcarriers\n",
        "#batch_size = tf.shape(y)[0]  # Or pass batch_size explicitly if available\n",
        "h_hat, err_var = _ls_est([y, no])\n",
        "# Tile h_hat across the batch dimension\n",
        "#h_hat = tf.tile(h_hat, [batch_size, 1, 1, 1, 1, 14, 1])\n",
        "x_hat, no_eff = _lmmse_equ([y, h_hat, err_var, no]) # LMMSE equalization\n",
        "no_eff_= expand_to_rank(no_eff, tf.rank(x_hat))\n",
        "llr = _demapper([x_hat, no_eff_]) # Demapping\n",
        "\n",
        "\n",
        "bce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr)\n",
        "bce = tf.reduce_mean(bce)\n",
        "rate = tf.constant(1.0, tf.float32) - bce/tf.math.log(2.)\n",
        "print(f\"Rate: {rate:.2E} bit\")"
      ],
      "metadata": {
        "id": "4-Kn4Wu29c-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ris.phase_profile.values = tf.zeros_like(ris.phase_profile.values)"
      ],
      "metadata": {
        "id": "Ee08Zww_27Re"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = scene.compute_paths(max_depth=5,\n",
        "                            num_samples=1e6)\n",
        "\n",
        "a, tau = paths.cir()\n",
        "# Compute frequencies of subcarriers and center around carrier frequency\n",
        "frequencies = subcarrier_frequencies(fft_size, subcarrier_spacing)\n",
        "\n",
        "# Compute the frequency response of the channel at frequencies.\n",
        "h_freq = cir_to_ofdm_channel(frequencies,\n",
        "                             a,\n",
        "                             tau,\n",
        "                             normalize=True)"
      ],
      "metadata": {
        "id": "ieca2Gzf4DrU"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_iterations = 300 # Number of training iterations\n",
        "training = True\n",
        "if training:\n",
        "    model = E2ESystem('neural-receiver', training=True)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    for i in range(num_training_iterations):\n",
        "        # Sampling a batch of SNRs\n",
        "        ebno_db = tf.random.uniform(shape=[], minval=ebno_db_min, maxval=ebno_db_max)\n",
        "        # Forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            rate = model(training_batch_size, ebno_db)\n",
        "            loss = - rate\n",
        "            print(loss.numpy())\n",
        "\n",
        "        # Computing and applying gradients\n",
        "        weights = model.trainable_weights\n",
        "        grads = tape.gradient(loss, weights)\n",
        "        optimizer.apply_gradients(zip(grads, weights))\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}  Rate: {:.4f} bit'.format(i, num_training_iterations, rate.numpy()), end='\\r')\n",
        "\n"
      ],
      "metadata": {
        "id": "Fj8pncvA4I9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_weights(model, model_weights_path):\n",
        "    weights = model.get_weights()\n",
        "    with open(model_weights_path, 'wb') as f:\n",
        "        pickle.dump(weights, f)\n",
        "save_weights(model, model_weights_path)\n",
        "# Range of SNRs over which the systems are evaluated\n",
        "ebno_dbs = np.arange(ebno_db_min, # Min SNR for evaluation\n",
        "                     ebno_db_max, # Max SNR for evaluation\n",
        "                     1) # Step\n",
        "# function to load and set weights of a model\n",
        "def load_weights(model, model_weights_path):\n",
        "    model(1, tf.constant(10.0, tf.float32))\n",
        "    with open(model_weights_path, 'rb') as f:\n",
        "        weights = pickle.load(f)\n",
        "    model.set_weights(weights)\n",
        "\n",
        "model = E2ESystem('baseline-perfect-csi')\n",
        "ber,_ = sim_ber(model, ebno_dbs, batch_size=64, num_target_block_errors=100, max_mc_iter=100)\n",
        "BER['baseline-perfect-csi'] = ber.numpy()\n",
        "\n",
        "model = E2ESystem('baseline-ls-estimation')\n",
        "ber,_ = sim_ber(model, ebno_dbs, batch_size=64, num_target_block_errors=100, max_mc_iter=100)\n",
        "BER['baseline-ls-estimation'] = ber.numpy()\n",
        "\n",
        "model = E2ESystem('neural-receiver')\n",
        "\n",
        "# Run one inference to build the layers and loading the weights\n",
        "model(1, tf.constant(10.0, tf.float32))\n",
        "with open(model_weights_path, 'rb') as f:\n",
        "    weights = pickle.load(f)\n",
        "model.set_weights(weights)\n",
        "\n",
        "# Evaluations\n",
        "ber,_ = sim_ber(model, ebno_dbs, batch_size=64, num_target_block_errors=100, max_mc_iter=100)\n",
        "BER['neural-receiver'] = ber.numpy()"
      ],
      "metadata": {
        "id": "973LkQiX4OoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_source = BinarySource()\n",
        "mapper = Mapper(\"qam\", num_bits_per_symbol)\n",
        "rg_mapper = ResourceGridMapper(resource_grid)\n",
        "#neural_receiver = model_conventional._neural_receiver\n",
        "rg_demapper = ResourceGridDemapper(resource_grid, stream_manager)\n",
        "channel = ApplyOFDMChannel(add_awgn=True)\n",
        "batch_size = 64\n",
        "ebno_db = tf.fill([batch_size], 5.0)\n",
        "no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n",
        "## Transmitter\n",
        "# Generate codewords\n",
        "c = binary_source([batch_size, 1, 1, n])\n",
        "print(\"c shape: \", c.shape)\n",
        "# Map bits to QAM symbols\n",
        "x = mapper(c)\n",
        "print(\"x shape: \", x.shape)\n",
        "# Map the QAM symbols to a resource grid\n",
        "x_rg = rg_mapper(x)\n",
        "print(\"x_rg shape: \", x_rg.shape)\n",
        "print(\"h_freq shape: \", h_freq.shape)\n",
        "######################################\n",
        "## Channel\n",
        "no_ = expand_to_rank(no, tf.rank(x_rg))\n",
        "print(\"no shape: \", no.shape)\n",
        "print(\"no_ shape: \", no_.shape)\n",
        "# Apply channel\n",
        "channel = ApplyOFDMChannel(add_awgn=True)\n",
        "y = channel([x_rg, h_freq, no])\n",
        "print(\"y shape: \", y.shape)\n",
        "######################################\n",
        "#_lmmse_equ = LMMSEEqualizer(resource_grid, stream_manager, )\n",
        "##_removed_null_subc = RemoveNulledSubcarriers(resource_grid)\n",
        "######################################\n",
        "## Receiver\n",
        "_lmmse_equ = LMMSEEqualizer(resource_grid, stream_manager)\n",
        "_demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n",
        "_ls_est = LSChannelEstimator(resource_grid, interpolation_type=\"nn\")\n",
        "# The neural receiver computes LLRs from the frequency domain received symbols and N0\n",
        "#y = tf.squeeze(y, axis=1)\n",
        "#h_hat = _removed_null_subc(h_freq) # Extract non-null subcarriers\n",
        "#batch_size = tf.shape(y)[0]  # Or pass batch_size explicitly if available\n",
        "h_hat, err_var = _ls_est([y, no])\n",
        "# Tile h_hat across the batch dimension\n",
        "#h_hat = tf.tile(h_hat, [batch_size, 1, 1, 1, 1, 14, 1])\n",
        "x_hat, no_eff = _lmmse_equ([y, h_hat, err_var, no]) # LMMSE equalization\n",
        "no_eff_= expand_to_rank(no_eff, tf.rank(x_hat))\n",
        "llr = _demapper([x_hat, no_eff_]) # Demapping\n",
        "\n",
        "bce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr)\n",
        "bce = tf.reduce_mean(bce)\n",
        "rate = tf.constant(1.0, tf.float32) - bce/tf.math.log(2.)\n",
        "print(f\"Rate: {rate:.2E} bit\")"
      ],
      "metadata": {
        "id": "xoJFoPz57oQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "# Baseline - Perfect CSI\n",
        "plt.semilogy(ebno_dbs, BER['baseline-perfect-csi'], 'o-', c=f'C0', label=f'Baseline - Perfect CSI')\n",
        "# Baseline - LS Estimation\n",
        "plt.semilogy(ebno_dbs, BER['baseline-ls-estimation'], 'x--', c=f'C1', label=f'Baseline - LS Estimation')\n",
        "# Neural receiver\n",
        "plt.semilogy(ebno_dbs, BER['neural-receiver'], 's-.', c=f'C2', label=f'Neural receiver')\n",
        "\n",
        "plt.semilogy(ebno_dbs, BER['baseline-perfect-csi-OpRIS'], 'o-', c=f'C6', label=f'baseline-perfect-csi-OpRIS')\n",
        "# Baseline - LS Estimation\n",
        "plt.semilogy(ebno_dbs, BER['baseline-ls-estimation-OpRIS'], 'x--', c=f'C4', label=f'baseline-ls-estimation-OpRIS')\n",
        "# Neural receiver\n",
        "plt.semilogy(ebno_dbs, BER['neural-receiver-OpRIS'], 's-.', c=f'C5', label=f'neural-receiver-OpRIS')\n",
        "#\n",
        "plt.xlabel(r\"$E_b/N_0$ (dB)\")\n",
        "plt.ylabel(\"BER\")\n",
        "plt.grid(which=\"both\")\n",
        "plt.ylim((1e-4, 1.0))\n",
        "plt.legend()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "ha7CCLCgCEoh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}